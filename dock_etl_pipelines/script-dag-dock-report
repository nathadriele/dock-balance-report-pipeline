import logging
import json
import requests
from datetime import date, timedelta, datetime
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python_operator import PythonOperator
from airflow.providers.amazon.aws.transfers.sftp_to_s3 import SFTPToS3Operator
from airflow.providers.amazon.aws.lambda_function import LambdaInvokeFunctionOperator
from airflow.providers.amazon.s3.operators.s3 import S3ListOperator
from airflow.providers.sftp.sensors.sftp import SFTPSensor

REMOTE_PATH = "dock/balances"
S3_PATH = "dock/balances"

default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 3,
    "retry_delay": timedelta(minutes=3),
}

def authenticate(**kwargs):
    """
    Autentica na API da Dock para obter o token de acesso.
    Lança exceção em caso de falha.
    """
    client_id = Variable.get("DOCK_CLIENT_ID")
    secret = Variable.get("DOCK_SECRET")
    url = Variable.get("DOCK_AUTH_URL")

    logging.info("Iniciando processo de autenticação...")

    try:
        response = requests.post(url, auth=(client_id, secret))
        response.raise_for_status()
        data = response.json()
        token = data.get("access_token")
    except Exception as err:
        logging.error("Erro ao tentar autenticar na Dock: %s", err)
        raise

    if not token:
        raise ValueError("Token de acesso não encontrado na resposta da API.")
    logging.info("Autenticação concluída com sucesso.")

    return token


def request_data(**kwargs):
    """
    Solicita o relatório de balanço via API da Dock.
    Salva o ticket retornado para uso posterior.
    """
    ti = kwargs["ti"]
    token = authenticate()
    day = (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")

    url_base = Variable.get("DOCK_TRANSACTIONS_URL")
    url = f"{url_base}?compressZipService=0&date=BALANCE&day={day}"
    
    headers = {
        "Authorization": token,
        "Accept": "application/json",
    }

    logging.info("Requisitando o relatório de balanço para o dia %s...", day)
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        result = response.json()
        ticket = result.get("ticket")
        if not ticket:
            raise ValueError("Ticket não encontrado na resposta da API.")
        ti.xcom_push(key="balance_ticket", value=ticket)
        logging.info("Relatório de balanço requisitado com sucesso. Ticket: %s", ticket)
    except Exception as err:
        logging.error("Erro ao requisitar o relatório de balanço: %s", err)
        raise


def get_ticket(**kwargs):
    """
    Recupera o arquivo de balanço via ticket retornado pela Dock e
    salva o nome do arquivo.
    """
    ti = kwargs["ti"]
    ticket = ti.xcom_pull(
        key="balance_ticket",
        task_ids="request_balance_report_task"
    )
    if not ticket:
        raise ValueError("O ticket não foi recuperado corretamente.")

    token = authenticate()
    url_base = Variable.get("DOCK_TRANSACTIONS_URL")
    url = f"{url_base}?ticket={ticket}"
    
    headers = {
        "Authorization": token,
        "Accept": "application/json",
    }

    logging.info("Recuperando arquivo de balanço com ticket %s...", ticket)
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        data = response.json()
        file_name = data.get("file")
        if not file_name:
            raise ValueError("Nome do arquivo não encontrado na resposta da API.")
        ti.xcom_push(key="balance_file_name", value=file_name)
        logging.info("Arquivo de balanço recuperado: %s", file_name)
    except Exception as err:
        logging.error("Erro ao recuperar o arquivo de balanço: %s", err)
        raise


def check_report(**kwargs):
    """
    Verifica se o arquivo de relatório está disponível no SFTP.
    """
    ti = kwargs["ti"]
    file_name = ti.xcom_pull(
        key="balance_file_name",
        task_ids="request_balance_ticket_task"
    )
    if not file_name:
        raise ValueError("Nome do arquivo não foi recuperado.")

    logging.info("Verificando disponibilidade do arquivo '%s' no SFTP...", file_name)

    sensor = SFTPSensor(
        task_id="wait_for_report_sensor",
        sftp_conn_id="dock_ssh",
        path=f"{REMOTE_PATH}/{file_name}",
        timeout=300,
        poke_interval=30,
    )

    try:
        sensor.execute(context=kwargs)
        logging.info("Arquivo '%s' já está disponível no SFTP.", file_name)
    except Exception as err:
        logging.error("Erro ao verificar disponibilidade do arquivo no SFTP: %s", err)
        raise


def transfer_data_to_s3(**kwargs):
    """
    Transfere o arquivo do SFTP para o bucket S3 configurado.
    """
    ti = kwargs["ti"]
    bucket = Variable.get("AWS_S3_BUCKET")
    file_name = ti.xcom_pull(
        key="balance_file_name",
        task_ids="request_balance_ticket_task"
    )
    if not file_name:
        raise ValueError("Nome do arquivo não foi recuperado.")

    logging.info("Iniciando transferência do arquivo '%s' para o S3 (%s)...", file_name, bucket)

    transfer_op = SFTPToS3Operator(
        task_id="transfer_files_to_s3_operator",
        sftp_conn_id="dock_ssh",
        s3_bucket=bucket,
        s3_key=f"{S3_PATH}/{file_name}",
        sftp_path=f"{REMOTE_PATH}/{file_name}",
        replace=True,
        confirm=True,
        use_temp_file=False
    )

    try:
        transfer_op.execute(context=kwargs)
        logging.info("Transferência do arquivo '%s' para S3 concluída.", file_name)
    except Exception as err:
        logging.error("Erro ao transferir o arquivo '%s' para o S3: %s", file_name, err)
        raise


def unzip_files(**kwargs):
    """
    Lista os arquivos ZIP no S3 e chama a função Lambda para descompactá-los.
    """
    bucket = Variable.get("AWS_S3_BUCKET")
    logging.info("Listando arquivos ZIP no bucket '%s' com prefixo '%s'...", bucket, S3_PATH)

    list_op = S3ListOperator(
        task_id="list_files_operator",
        bucket=bucket,
        prefix=S3_PATH,
    )
    
    try:
        s3_files = list_op.execute(context=kwargs)
        zip_files = [file for file in s3_files if file.endswith(".zip")]

        if not zip_files:
            logging.info("Nenhum arquivo ZIP encontrado para descompactar.")
            return

        logging.info("Arquivos ZIP encontrados: %s", zip_files)
        logging.info("Invocando função Lambda para descompactar os arquivos...")

        lambda_op = LambdaInvokeFunctionOperator(
            task_id="dock_unzip_files_operator",
            function_name="dock_unzip_files",
            payload=json.dumps({"bucket": bucket, "keys": zip_files}),
        )

        lambda_op.execute(context=kwargs)
        logging.info("Função Lambda executada com sucesso para descompactação.")

    except Exception as err:
        logging.error("Erro ao descompactar arquivos via Lambda: %s", err)
        raise

with DAG(
    dag_id="dock_balance_report",
    description="DAG para extrair relatórios de balanço da Dock via SFTP e armazenar/descompactar no S3",
    default_args=default_args,
    start_date=datetime(2024, 12, 15),
    schedule_interval="30 8 * * *",
    catchup=False,
    max_active_runs=1,
    tags=["etl", "dock", "balance"]
) as dag:

    request_report_task = PythonOperator(
        task_id="request_balance_report_task",
        python_callable=request_data,
        provide_context=True,
    )

    request_ticket_task = PythonOperator(
        task_id="request_balance_ticket_task",
        python_callable=get_ticket,
        provide_context=True,
    )

    wait_for_report_task = PythonOperator(
        task_id="wait_for_report_task",
        python_callable=check_report,
        provide_context=True,
    )

    transfer_report_to_s3_task = PythonOperator(
        task_id="transfer_report_to_s3_task",
        python_callable=transfer_data_to_s3,
        provide_context=True,
    )

    unzip_report_task = PythonOperator(
        task_id="unzip_report_task",
        python_callable=unzip_files,
        provide_context=True,
    )

    (
        request_report_task
        >> request_ticket_task
        >> wait_for_report_task
        >> transfer_report_to_s3_task
        >> unzip_report_task
    )